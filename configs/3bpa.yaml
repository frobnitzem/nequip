run: [train, test]

cutoff_radius: 5.0
chemical_symbols: [C, H, N, O]
model_type_names: ${chemical_symbols}

data:
  _target_: nequip.data.datamodule.NequIP3BPADataModule
  data_source_dir: dataset_3BPA
  test_sets: ["300K", "600K", "1200K"]
  seed: 456
  transforms:
    - _target_: nequip.data.transforms.NeighborListTransform
      r_max: ${cutoff_radius}
    - _target_: nequip.data.transforms.ChemicalSpeciesToAtomTypeMapper
      chemical_symbols: ${chemical_symbols}
  train_val_split: [450, 50]
  train_dataloader_kwargs:
    batch_size: 5
    num_workers: 5
    shuffle: true
  val_dataloader_kwargs:
    batch_size: 5
    num_workers: ${data.train_dataloader_kwargs.num_workers}
  test_dataloader_kwargs: ${data.val_dataloader_kwargs}
  stats_manager:
    _target_: nequip.data.DataStatisticsManager
    metrics:
      - field:
          _target_: nequip.data.NumNeighbors
        metric: 
          _target_: nequip.data.Mean
        name: num_neighbors_mean
      - field: forces
        metric:
          _target_: nequip.data.RootMeanSquare
        name: forces_rms

trainer:
  _target_: lightning.Trainer
  accelerator: gpu
  enable_checkpointing: true
  max_epochs: 100000
  max_time: 03:00:00:00
  check_val_every_n_epoch: 1  
  log_every_n_steps: 20       

  logger:
    _target_: lightning.pytorch.loggers.wandb.WandbLogger
    project: nequip
    name: 3bpa
    save_dir: ${hydra:runtime.output_dir}

  callbacks:

    - _target_: lightning.pytorch.callbacks.ModelCheckpoint
      monitor: val0_epoch/weighted_sum
      dirpath: ${hydra:runtime.output_dir}   
      filename: best                         
      save_last: true

    - _target_: lightning.pytorch.callbacks.EarlyStopping
      monitor: val0_epoch/weighted_sum
      min_delta: 5e-4
      patience: 100

    - _target_: lightning.pytorch.callbacks.LearningRateMonitor
      logging_interval: epoch

    - _target_: nequip.train.callbacks.NeMoExponentialMovingAverage
      decay: 0.995
      every_n_steps: 1

training_module:
  _target_: nequip.train.NequIPLightningModule

  loss:
    _target_: nequip.train.MetricsManager
    metrics:
      - name: peratomE_MSE
        field: total_energy
        mode: per_atom
        coeff: 1
        metric:
          _target_: nequip.train.MeanSquaredError
      - name: force_MSE
        field: forces
        coeff: 1e5
        metric:
          _target_: nequip.train.MeanSquaredError

  val_metrics:
    _target_: nequip.train.MetricsManager
    metrics:
      - name: E_RMSE
        field: total_energy
        coeff: 1
        metric:
          _target_: nequip.train.RootMeanSquaredError
      - name: F_RMSE
        field: forces
        coeff: 1
        metric:
          _target_: nequip.train.RootMeanSquaredError

  test_metrics:
    _target_: nequip.train.MetricsManager
    metrics:
      - name: E_RMSE
        field: total_energy
        metric:
          _target_: nequip.train.RootMeanSquaredError
      - name: F_RMSE
        field: forces
        metric:
          _target_: nequip.train.RootMeanSquaredError

  optimizer:
    _target_: torch.optim.Adam
    lr: 0.015
    amsgrad: true

  lr_scheduler:
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      patience: 20
      factor: 0.8
      threshold: 0.0
    monitor: val0_epoch/weighted_sum
    interval: epoch
    frequency: 1

  model:
    _target_: nequip.model.NequIPGNNModel
    # == basic model params ==
    seed: 76
    model_dtype: float32
    type_names: ${model_type_names}
    r_max: ${cutoff_radius}
    # == bessel encoding ==
    polynomial_cutoff_p: 2
    # == general params ==
    num_layers: 4
    l_max: 3
    parity: true
    num_features: 64
    invariant_layers: 3           
    invariant_neurons: 32    
    avg_num_neighbors: ${training_data_stats:num_neighbors_mean}
    # == scale shifts ==
    # isolated atom energies from dataset
    per_type_energy_shifts: [-1029.4889999855063, -13.587222780835477, -1484.9814568572233, -2041.9816003861047]
    per_type_energy_scales: ${training_data_stats:forces_rms}
    per_type_energy_shifts_trainable: false
    per_type_energy_scales_trainable: false
   

# global options
global_options:
  seed: 789
  allow_tf32: false